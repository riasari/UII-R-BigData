---
title: "Machine Learning"
output: html_notebook
---

Load spark

```{r}
library(sparklyr)
library(dplyr)
library(ggplot2)
library(arrow)
conf <- spark_config()
conf$`sparklyr.shell.driver-memory` <- "8G"
spark <- spark_connect(master = "local", config = conf)
```

sparklyr provides bindings to Sparkâ€™s distributed machine learning library. In particular, sparklyr allows you to access the machine learning routines provided by the spark.ml package.

https://spark.rstudio.com/mlib/ outlines a list of supported algorithms.


```{r}
iris_tbl <- copy_to(spark, iris, "iris", overwrite = TRUE)
head(iris_tbl)

kmeans_model <- iris_tbl %>%
  select(Petal_Width, Petal_Length) %>%
  ml_kmeans(~ ., k = 3)

kmeans_model

# predict the associated class
predicted <- ml_predict(kmeans_model, iris_tbl) %>%
  collect
base::table(predicted$Species, predicted$prediction)

# plot cluster membership
ml_predict(kmeans_model) %>%
  collect() %>%
  ggplot(aes(Petal_Length, Petal_Width)) +
  geom_point(aes(Petal_Width, Petal_Length, col = factor(prediction + 1)),
             size = 2, alpha = 0.5) + 
  geom_point(data = kmeans_model$centers, aes(Petal_Width, Petal_Length),
             col = scales::muted(c("red", "green", "blue")),
             pch = 'x', size = 12) +
  scale_color_discrete(name = "Predicted Cluster",
                       labels = paste("Cluster", 1:3)) +
  labs(
    x = "Petal Length",
    y = "Petal Width",
    title = "K-Means Clustering",
    subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
  )
```

Another example ALS:
```{r}
movies <- data.frame(user   = c(1, 2, 0, 1, 2, 0),
                     item   = c(1, 1, 1, 2, 2, 0),
                     rating = c(3, 1, 2, 4, 5, 4))

copy_to(spark, movies) %>%
  ml_als(rating ~ user + item) %>%
  augment()
```

## Pipelines

Pipelines(https://spark.rstudio.com/guides/pipelines/) are a great way to combine a multi step ML process into a neat object which can easily be cross-validated or reused.

> Spark is just a tool to run machine learning models on larger data!
Make sure to understand the concepts of machine learning without spark first.

There are many more machine learning models out there which are not supported by spark. But as shown in section UADF it is quite simple to parallelize these using sparklyR.

Be sure to check out https://github.com/harryprince/awesome-sparklyr and particularly
- https://github.com/rstudio/mleap
- https://github.com/mlflow/mlflow/tree/master/mlflow/R/mlflow
which are well suited for production serving of ML models.

## lab task
Many more algorithms can be explored at https://spark.rstudio.com/mlib/ go through them as a lab exercise. Also look at https://spark.rstudio.com/graphframes/ and https://github.com/rstudio/sparkxgb and the other links from https://github.com/harryprince/awesome-sparklyr

## cleanup

Finally, close the spark session again.
```{r}
spark_disconnect(spark)
```
